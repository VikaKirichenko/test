# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yjY7TfIEur9W5bkodDRrFRCTO9_L1Bhr
"""

import pandas as pd

"""Создадим пустой daraframe"""

data = []
df = pd.DataFrame(data, columns=['id', 'Город_дистрибьютора','Торг_точка_грязная','Торг_точка_грязная_адрес','outlet_clean_id'])

"""распарсим данные из файла в dataframe"""

f = open('outlets.txt', 'r')
for line in f:
    if line.startswith("("):
        line = line.replace("(","")
        line = line.replace(")","")
        line = line[:-1]
        data = line.split('\' ')
        data = data[0]
        l = ['"{}"'.format(s) for s in data.split('\'') if s not in ('', ', ')]
        l = [elem.replace(",","").replace("\"","").strip() for elem in l]
        # break
        # print(l)
        dict = {'id': l[0], 'Город_дистрибьютора': l[1], 'Торг_точка_грязная': l[2],'Торг_точка_грязная_адрес':l[3],'outlet_clean_id':l[4]}
        df = df.append(dict,  ignore_index = True)

df.head()

"""Удалим колонку 'Город_дистрибьютора', т.к. значение в ней у всех одинаковое"""

df = df.drop(columns=['Город_дистрибьютора'])

df.head()

df['addr'] = df['Торг_точка_грязная']+df['Торг_точка_грязная_адрес']

df.head()

"""Реализация препроцессинга текста: удаление спец символов, стоп-слов,приведение к нижнему регистру"""

import regex as re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
STOPWORDS = stopwords.words('english')
STOPWORDS = set(STOPWORDS)
    
def text_prepare(text, STOPWORDS):
    """
        text: a string
        
        return: a clean string
    """
    REPLACE_BY_SPACE_RE = re.compile('[\n\"\'/(){}\[\]\|@,;#]')
    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text)
    text = re.sub(' +', ' ', text)
    text = text.lower()

    # delete stopwords from text
    text = ' '.join([word for word in text.split() if word not in STOPWORDS]) 
    text = text.strip()
    return text

df['addr'] = df['addr'].apply(lambda x: text_prepare(x,STOPWORDS))

df.head()

from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans
def get_similarity_matrix(df, threshold):
    """
    Функция, соединяющая функции для получения топков

    Parameters
    ----------
    df : DataFrame
        Таблица с центрами, топ словами, векторным представлением и весами слов для каждого топика
    threshold : float
        трешхолд для отбора похожих топиков

    Returns
    -------
    df : DataFrame
        Таблица со значениями косинусных расстояний между центрами топиков
    similar_topics : list
        Список топиков, похожесть которых выше указанного порога
    """
    matrix = []
    similar_topics = []
    for i in range(len(df['centers'])):
        row = []
        for j in range(len(df['centers'])):
            dist = cosine_similarity(df['centers'][i], df['centers'][j])  # cosine_similarity
            row.append(dist[0][0])
            if j > i and dist[0][0] > threshold:
                similar_topics.append((df['id'][i], df['id'][j]))
        matrix.append(row)

    df = pd.DataFrame(matrix)
    return df, similar_topics

def get_center(top_feat):
    """
    Функция, находящая центр одного топика методом kmeans

    Parameters
    ----------
    top_feat : list
        Массив топ признаков топика
    Returns
    -------
    list
        Центр кластера
    """
    kmeans = KMeans(n_clusters=1)
    kmeans.fit(top_feat)
    kmeans.predict(top_feat)
    return kmeans.cluster_centers_

df.head()

"""Создание нового dataframe, чтобы при нахождении похожих топиков, удалять не из исходого датасета, а из нового (в последствии этот датасет и окажется таблицей `outlets_clean`)"""

new_df = df[['id','addr','outlet_clean_id']]

new_df.head()

"""Векторизуем тексты наиболее популярной и пройстой векторизацией tf-idf"""

import sklearn
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=5, token_pattern='(\S+)')
X = tfidf_vectorizer.fit_transform(new_df['addr'])
X1 = X.toarray()
# new_df['transformed'] = X1

new_df.tail()

"""Сопоставим каждому тексту его векторизованное представление в datafrme"""

centers = []
for item in X1:
    centers.append(item.reshape(1,-1))

new_df['centers'] = centers

"""В следующем блоке кода реализуется нахождение дубликатов (похожих) адресов

Для этого ранее была реализована функция `get_similarity_matrix`, которая высчитывает косинусное расстояние между векторами, на основе полученных результатов, задаем кластер, если был у первого, то и второму задаем тот же кластер, если у первого нет, но у второго есть, то первому задаем класс второго, если ни у кого нет, то создаем новый посредством постепенного увеличения переменной `id`
"""

similarity_matrix, similar_topics = get_similarity_matrix(new_df, 0.7)
id = 1
while len(similar_topics) > 0:
    # дать номер кластера двум адресам одинаковый
    i = similar_topics[0][0]
    j = similar_topics[0][1]
    if df[df['id']==i]['outlet_clean_id'] != "NULL":
        df[df['id']==j]['outlet_clean_id'] = df[df['id']==i]['outlet_clean_id']
        new_df[new_df['id']==i]['outlet_clean_id'] = df[df['id']==i]['outlet_clean_id']
    elif df[df['id']==j]['outlet_clean_id'] != "NULL":
        df[df['id']==i]['outlet_clean_id'] = df[df['id']==j]['outlet_clean_id']
        new_df[new_df['id']==i]['outlet_clean_id'] = df[df['id']==j]['outlet_clean_id']
    else:
        df[df['id']==j]['outlet_clean_id'] = id
        df[df['id']==i]['outlet_clean_id'] = id
        new_df[new_df['id']==i]['outlet_clean_id'] = id
        id+=1
    new_df = new_df.drop(new_df[new_df['id'] == j].index)

    similarity_matrix, similar_topics = get_similarity_matrix(new_df, 0.7)

"""Для итоговых таблиц необходимо удалить из датасета df колонку addr, а из датасета new_df колонки `id`,`centers`,а также переименовать `outlet_clean_id` в `id`"""

new_df = new_df.drop(columns = ["id","centers"])
new_df.rename(columns={"outlet_clean_id": "id"})
df = df.drop(columns = ['addr'])

"""Сохраним полученные результаты в файлы"""

df.to_csv("outlets",index=False)
new_df.to_csv("outlets_clean",index=False)